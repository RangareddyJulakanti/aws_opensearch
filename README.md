# ğŸ” AWS OpenSearch Manager & Exporter

This project serves as a comprehensive toolkit for managing data in **Amazon OpenSearch Serverless (AOSS)**. It provides a modern user interface for data entry and search, along with robust scripts for data extraction and cloud-native backup processes.

---

## ğŸ—ï¸ Architecture

The system consists of three main interaction points with the OpenSearch cluster:

```mermaid
flowchart TD
    subgraph Client["ğŸ’» Local Environment"]
        UI["ğŸ–¥ï¸ Streamlit App (ui.py)"]
        CLI["ğŸ“Ÿ CLI Tools (app.py)"]
        Downloader["ğŸ“¥ Downloader (download_data.py)"]
    end

    subgraph AWS["â˜ï¸ AWS Cloud"]
        AOSS[("ğŸ” Amazon OpenSearch Serverless")]
        Lambda["âš¡ AWS Lambda (lambda_function.py)"]
        S3[("ğŸª£ Amazon S3 Bucket")]
    end

    %% Connections
    %% Connections
    UI <-->|Read/Write| AOSS
    CLI <-->|Read/Write| AOSS
    AOSS -->|Stream Data| Downloader
    AOSS -->|Stream Data| Lambda
    Lambda -->|Export NDJSON| S3
    
    %% Styles
    style AOSS fill:#ff9900,stroke:#333,stroke-width:2px
    style Lambda fill:#ff9900,stroke:#333,stroke-width:2px
    style S3 fill:#388e3c,stroke:#333,stroke-width:2px,color:white
```

### ğŸ”„ S3 Backup Workflow (Sequence Diagram)

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User/EventBridge
    participant L as âš¡ AWS Lambda
    participant A as ğŸ” OpenSearch (AOSS)
    participant S as ğŸª£ S3 Bucket

    U->>L: Trigger Export (JSON Event)
    activate L
    L->>A: 1. Request Data (Scroll/SearchAfter)
    activate A
    A-->>L: Return Documents (Batch 1)
    deactivate A
    L->>L: Write to /tmp (NDJSON)
    
    loop Pagination
        L->>A: Request Next Batch (Sort Key)
        A-->>L: Return Documents
        L->>L: Append to /tmp
    end
    
    L->>S: 2. Upload File (PutObject)
    activate S
    S-->>L: Success (200 OK)
    deactivate S
    
    L-->>U: Return Success Report
    deactivate L
```

### ğŸ§­ User Flow (Streamlit)

```mermaid
graph LR
    User((ğŸ‘¤ User)) --> Start[Open App]
    Start --> Dashboard{View Dashboard}
    
    Dashboard -->|Check Status| Health[ğŸŸ¢ Cluster Health]
    Dashboard -->|Manage Indexes| Create[âœ¨ Create New Index]
    
    Start --> Entry[ğŸ“ Data Entry]
    Entry -->|Submit Form| Insert[POST Document]
    Insert -->|Indexing| AOSS[("ğŸ” OpenSearch")]
    
    Start --> Search[ğŸ” Search Explorer]
    Search -->|Type Query| Query[GET /_search]
    Query -->|Fetch Results| AOSS
    AOSS -->|Return Hits| Display[ğŸ“‹ View Results Cards]
```

---

## ğŸ“¦ Components

### 1. ğŸ–¥ï¸ OpenSearch Manager UI (`ui.py`)
A modern web interface built with **Streamlit**.
-   **Dashboard**: Visualize cluster health, active indexes, and doc counts.
-   **Data Entry**: User-friendly form to insert documents without writing queries.
-   **Search Explorer**: Real-time search with rich result cards.
-   **Compatability**: Works with both Provisioned and Serverless (AOSS) endpoints.

### 2. âš¡ Data Exporter (`download_data.py`)
A robust script designed for large dataset extraction.
-   **Method**: Uses `search_after` (deep pagination) to bypass the 10,000 document limit.
-   **Efficiency**: Streams data directly to a local file (NDJSON format) to minimize memory usage for files >1GB.
-   **Sorting**: Defaults to `_id` sorting to ensure compatibility with AOSS.

### 3. â˜ï¸ AWS Lambda Backup (`lambda_function.py`)
A serverless function to automate backups.
-   **Function**: Downloads index data to `/tmp` and uploads it to an **Amazon S3** bucket.
-   **Trigger**: Can be triggered via EventBridge (Cron) for daily/weekly backups.
-   **Local Test**: Can be executed locally to verify logic before deployment.

### 4. ğŸ”— Shared Utilities (`utils.py`)
Centralized connection logic used by all components to ensure secure and consistent authentication using `boto3` and `opensearch-py`.

---

## ğŸš€ Getting Started

### Prerequisites
1.  **Python 3.8+**
2.  **AWS Credentials** configured (via `aws configure` or environment variables).
3.  **Amazon OpenSearch Serverless Collection** created.

### Installation
```bash
# Create virtual environment
python -m venv venv
./venv/Scripts/activate

# Install dependencies
pip install . 
# Or: pip install streamlit opensearch-py requests-aws4auth boto3 pandas python-dotenv
```

### Configuration
Create a `.env` file in this directory:
```bash
OPENSEARCH_URL=https://<your-collection-id>.us-east-1.aoss.amazonaws.com
AWS_REGION=us-east-1
OUTPUT_BUCKET=<your-s3-bucket-name>  # For Lambda export
```

---

## ğŸ“– Usage Guide

### 1. Run the UI
Access the graphical dashboard at `http://localhost:8501`.
```bash
streamlit run ui.py
```

### 2. Export Data Locally
Download an entire index to `inventory_data.jsonl`.
```bash
# Usage: python download_data.py <index_name>
python download_data.py inventory
```

### 3. Run S3 Export (Local Test)
Test the Lambda logic locally to backup data to S3.
```bash
# Usage: python lambda_function.py <index_name> <bucket_name>
python lambda_function.py inventory my-backup-bucket
```

---

## âš ï¸ Important Notes
-   **Permissions**: Ensure your IAM user/role has permission to access the OpenSearch collection (`aoss:APIAccessAll`) and write to the S3 bucket (`s3:PutObject`).
-   **Serverless (AOSS)**: This project includes specific fixes for AOSS quirks (e.g., handling 404 on root info info checks, using `_id` sorting instead of `_seq_no`).
